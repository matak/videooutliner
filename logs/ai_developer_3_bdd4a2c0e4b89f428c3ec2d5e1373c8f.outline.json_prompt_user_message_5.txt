Transcript:

=================
1027
01:13:00,979 --> 01:13:05,619
prostě to je způsob, jakým vy ovlivňujete chování tý aplikace,

1028
01:13:05,659 --> 01:13:09,840
tím, že prostě při deploymentu změníte nějakou hodnotu v EnviroVent Variable,

1029
01:13:10,279 --> 01:13:15,659
nějaký feature flag prostě a tím si zapnete v tý aplikaci nějakou celou feature.

1030
01:13:16,119 --> 01:13:20,020
Takže je to způsob, jak vy můžete ovlivňovat to, co se děje v tom kódu,

1031
01:13:20,020 --> 01:13:22,899
bez toho, aniž byste museli něco měnit v tom kódu.

1032
01:13:23,159 --> 01:13:26,100
Asi takhle doufám, že se to vysvětlo dobře.

1033
01:13:27,559 --> 01:13:30,899
Nebo dobře jsem to vysvětlil, ale pochopitelně.

1034
01:13:31,659 --> 01:13:38,260
Tak, v tom, co říká,

1035
01:13:38,319 --> 01:13:42,079
How do I embed Confluence, Wikipages, SQL, Python,

1036
01:13:42,079 --> 01:13:45,779
Java code snippets also into Instruct Models?

1037
01:13:47,500 --> 01:13:48,279
Yes, Alex.

1038
01:13:50,119 --> 01:13:52,979
Vy ho vždycky budete učit vlastně jenom ty odpovědi.

1039
01:13:53,039 --> 01:13:54,699
To je to, co si musíte uvědomit.

1040
01:13:54,739 --> 01:13:57,720
Takže nehledě na to vlastně, co ho chcete učit,

1041
01:13:58,779 --> 01:14:01,300
vždycky mu musíte dát příklad toho,

1042
01:14:02,399 --> 01:14:06,059
jak chcete, aby odpovídal. Takhle se to snažte pochopit.

1043
01:14:06,079 --> 01:14:11,340
To znamená, že v tom souboru, znova nehledě na to,

1044
01:14:11,440 --> 01:14:14,940
co ho budete chtít učit, tak on se vždycky bude učit

1045
01:14:14,960 --> 01:14:20,779
vlastně to assistant. To znamená, že na základě téhle otázky

1046
01:14:20,779 --> 01:14:23,359
já chci po tobě, aby si mi odpověděl tímhle způsobem.

1047
01:14:23,359 --> 01:14:26,159
A teď už je jedno, jestli vy mu dáte příklady jako...

1048
01:14:27,920 --> 01:14:32,739
kdy mu dám strukturu databáze a dám mu otázku,

1049
01:14:32,859 --> 01:14:35,260
potřebuji vytvořit novou objednávku,

1050
01:14:35,260 --> 01:14:38,479
a výstupem bude prostě správnej SQL dotaz.

1051
01:14:39,000 --> 01:14:42,819
Nebo to bude text, který to má vlastně tomu uživateli vrátit.

1052
01:14:42,819 --> 01:14:44,840
To už je prostě na vás, ale vždycky to bude

1053
01:14:46,020 --> 01:14:49,159
v tomhle konverzačním formátu.

1054
01:14:54,100 --> 01:14:56,119
Tak, pálí mi hrozně žáha, já se tady...

1055
01:14:56,119 --> 01:14:57,720
Jenom nebojí.

1056
01:15:04,399 --> 01:15:04,819
...

1057
01:15:08,159 --> 01:15:12,840
To je například nastavení API haslaku OpenAI, je to konfigurační fakt,

1058
01:15:13,000 --> 01:15:16,359
který zjistí jasně environment, jasně, co si přechtěte.

1059
01:15:17,119 --> 01:15:19,640
Takže kdyby ten model ať to naučí interní dokumentaci firmy,

1060
01:15:19,640 --> 01:15:22,880
tak musím posunout ve formátu konverzace nebo otázkotvě.

1061
01:15:22,899 --> 01:15:28,039
Přesně tak, tak pojďme se na to podívat, ať se vám to trošku zjednoduší to chápání.

1062
01:15:30,239 --> 01:15:33,359
Já tady přeskočím na domain knowledge, pak si podívám na ty tooly,

1063
01:15:33,359 --> 01:15:36,779
protože to je asi to, co vás zajímá, to zajímá spoustu lidí.

1064
01:15:37,760 --> 01:15:41,680
jak ho naučit novou znalost, něco u vaší firmě,

1065
01:15:42,359 --> 01:15:45,039
nebo něco, co on neví.

1066
01:15:45,220 --> 01:15:49,579
Takže já to budu demonstrovat na autogendokumentaci,

1067
01:15:50,380 --> 01:15:53,500
to znamená, že co jsem udělal v těch datech,

1068
01:15:53,500 --> 01:16:01,640
které máte k dispozici, je ta autogendokumentace.

1069
01:16:01,640 --> 01:16:03,180
PDFka jsou prostě blbý.

1070
01:16:03,399 --> 01:16:06,260
PDFka, to si zvykněte, to je prostě problém.

1071
01:16:06,440 --> 01:16:08,220
Je to sice hezký načtení pro lidi,

1072
01:16:08,279 --> 01:16:11,059
ale pro AI je to prostě pain in the ass.

1073
01:16:12,239 --> 01:16:13,819
procesovat. Má to obrázky,

1074
01:16:15,340 --> 01:16:16,760
teď budete to procesovat

1075
01:16:16,760 --> 01:16:18,579
jako obrázky, ty stránky

1076
01:16:18,699 --> 01:16:20,520
toho PDFka, nebo z toho chcete

1077
01:16:20,520 --> 01:16:22,899
dostat ten text. Teď ten text,

1078
01:16:22,920 --> 01:16:24,559
jak tady někdo uváděl, už máte ve více

1079
01:16:24,680 --> 01:16:26,979
sloupcích, bude on rozumět,

1080
01:16:26,979 --> 01:16:28,539
že prostě zazoují dva

1081
01:16:28,819 --> 01:16:31,180
jiné sloupce, které se čtou jeden a druhej

1082
01:16:31,180 --> 01:16:32,899
a ne takhle jako přes sebe

1083
01:16:33,340 --> 01:16:35,779
řádky. To znamená, že

1084
01:16:35,779 --> 01:16:37,420
mnohem jednodušší je používat texták

1085
01:16:37,420 --> 01:16:39,140
nebo nejlépe Markdown. Markdown

1086
01:16:39,520 --> 01:16:40,220
má tu výhodu, že

1087
01:16:42,539 --> 01:16:45,640
Markdal má tu výhodu, že tam má nějaký způsob formatování,

1088
01:16:45,640 --> 01:16:48,479
který mu ty AI modely rozumějí.

1089
01:16:48,559 --> 01:16:53,500
Takže vědět, co jsou nadpisy, vědět, že dva tyhle hashtagy

1090
01:16:53,659 --> 01:16:59,440
jsou prostě nadpis druhý úrovně, hashtag jeden je nadpis první úrovně,

1091
01:16:59,440 --> 01:17:02,819
tady máte tučnej text, tady máte nějaký pořadí.

1092
01:17:02,819 --> 01:17:04,659
To je mnohem lepší format.

1093
01:17:04,779 --> 01:17:07,699
To znamená, že to, co já jsem udělal, je, že jsem si z toho PDF-ka

1094
01:17:07,739 --> 01:17:09,520
vytáhal prostě ty texty.

1095
01:17:09,840 --> 01:17:23,899
A vykašlal jsem se na obrázky, mohl bych mu tam dát ty obrázky v nějaké URL adrese, ale to bych zase musel mluvit s chat GPT, aby on si ty obrázky vytáhl z té URL adresy, takže já se zaměřujeme čistě na text.

1096
01:17:24,020 --> 01:17:31,979
Takže z toho PDFka jsem si vytáhal vlastně ty texty a dal jsem je do nějakého ideálního formátu, čili markdownu.

1097
01:17:32,779 --> 01:17:36,079
A teď jsem dělal prompt engineering.

1098
01:17:36,079 --> 01:17:40,800
To je to, co i budu ukazovat, jak dělat v nějaký pokročilejší formě,

1099
01:17:40,800 --> 01:17:43,600
když budu připravovat daty na ty tool selection.

1100
01:17:43,979 --> 01:17:52,479
Pro tenhle případ je to velmi jednoduchý prompt engineering,

1101
01:17:52,479 --> 01:17:54,559
neboli připravování dat.

1102
01:17:55,140 --> 01:17:59,800
Vzal jsem ten Markdown, hodil jsem ho do ChitGPT,

1103
01:18:00,300 --> 01:18:07,880
když tak postupně, a řeptal jsem se, hele, vygeneruj mi 10 otázek na tenhle text,

1104
01:18:07,920 --> 01:18:15,440
který jsem udal do kontextu. A on mi začal generovat 10 otázek, otázka a odpověď.

1105
01:18:15,819 --> 01:18:21,979
A tyhle data já jsem nazbíral, je to dohromady nějakých, já si nepamatuju, nějakých 200 otázek,

1106
01:18:22,380 --> 01:18:25,619
a tyhle data ohledně toho textu

1107
01:18:25,979 --> 01:18:30,500
já budu nalejovat, nebo budu potom připravovat

1108
01:18:30,819 --> 01:18:36,940
ve formátu otázka-odpověď, takže uživatel-asistent, uživatel-asistent, uživatel-asistent.

1109
01:18:37,600 --> 01:18:41,739
tak, aby on si zapamatoval, co to ten autogen je.

1110
01:18:42,340 --> 01:18:44,539
Takže typy otázku, co je autogen,

1111
01:18:44,539 --> 01:18:48,300
jak komunikují agenti v autogenu, zase.

1112
01:18:48,680 --> 01:18:54,800
Můžeš mi vysvětlit, jak kustomizovat nějaké aspekty autogen a agentů.

1113
01:18:54,800 --> 01:18:57,260
A zase, všechno je to alebrané z toho textu.

1114
01:18:57,260 --> 01:18:59,000
Takže když bude o vaší firmě,

1115
01:18:59,819 --> 01:19:03,359
tak typicky si musíte na to podívat těma očima

1116
01:19:04,140 --> 01:19:06,600
konverzace. Takže když to budou

1117
01:19:06,739 --> 01:19:08,920
materiály, nějaké marketingové materiály

1118
01:19:08,960 --> 01:19:10,500
prostě o firmě, která

1119
01:19:10,579 --> 01:19:12,479
prodává střešní tašky,

1120
01:19:12,899 --> 01:19:14,579
tak budete pravděpodobně vytvářet

1121
01:19:14,659 --> 01:19:16,520
ten dataset ve formátu jako

1122
01:19:16,840 --> 01:19:18,399
doporučte mi

1123
01:19:18,399 --> 01:19:20,920
nejlevnější tašky,

1124
01:19:20,920 --> 01:19:22,940
který máte, nebo nejdvrdší tašky,

1125
01:19:22,940 --> 01:19:24,680
který máte, nebo které tašky se můžou

1126
01:19:24,699 --> 01:19:26,420
hodit na mojí střechu. A teď

1127
01:19:26,479 --> 01:19:27,279
je

1128
01:19:27,500 --> 01:19:30,659
Takhle budete připravovat vlastně ty data na tu konverzaci.

1129
01:19:30,699 --> 01:19:35,159
Musíte se vžít do té role, co ty uživatelé tak jako by se můžou ptát

1130
01:19:35,180 --> 01:19:40,079
a jaký odpovědi vlastně vy chcete, aby ta umělá inteligence dávala.

1131
01:19:41,159 --> 01:19:44,159
Berte to tak, že připravíte částečný vlastně dataset,

1132
01:19:44,940 --> 01:19:52,800
to natrénujete tu umělou inteligenci. A ona už v tom, vlastně v tomhle tom kontextu se dokáže pohybovat sama.

1133
01:19:52,800 --> 01:20:04,020
Takže není to tak, jako že by vy jste připravovali nějakou fulltextovou databázi, kde by podle typu otázky se vlastně vybrala ta...

1134
01:20:10,239 --> 01:20:14,940
kombinace otázek a odpovědí.

1135
01:20:15,000 --> 01:20:16,319
Stačí jenom, když mu dáte takové

1136
01:20:16,440 --> 01:20:18,559
námět k tomu,

1137
01:20:18,880 --> 01:20:20,220
aby on se pak mohl

1138
01:20:20,220 --> 01:20:21,020
v rámci tohohle

1139
01:20:21,819 --> 01:20:24,380
těch hranic

1140
01:20:24,500 --> 01:20:25,979
pohybovat sám.

1141
01:20:27,059 --> 01:20:28,399
Mně tady stačilo nějakých 200

1142
01:20:29,159 --> 01:20:31,159
otázek a on už

1143
01:20:31,479 --> 01:20:32,300
navnímal, o čem ten

1144
01:20:32,300 --> 01:20:35,119
autogen je a jak by měl asi tak

1145
01:20:35,300 --> 01:20:35,979
odpovídat.

1146
01:20:38,559 --> 01:20:45,479
Tak, jo, a teďka tady někdo správně odpovídá.

1147
01:20:45,600 --> 01:20:48,579
Osobní názor je takový, že by tam byla lepší varianta integrace RAGU.

1148
01:20:48,579 --> 01:20:56,460
Ano, to je druhá možnost, kterou vy máte vlastně ty dokumenty nalejt do RAGOvý databáze

1149
01:20:57,180 --> 01:21:00,739
a vlastně při tom, když ten uživatel se zeptá,

1150
01:21:00,979 --> 01:21:06,220
tak to vaše API by si vlastně vyselektilo relevantní data z té databáze.

1151
01:21:07,000 --> 01:21:09,760
přiložilo, připláclo by to k té otázce

1152
01:21:09,779 --> 01:21:11,600
toho uživatele do kontextu

1153
01:21:12,059 --> 01:21:13,840
a poslalo by to do toho modelu.

1154
01:21:13,840 --> 01:21:15,600
To je jediné, co ten hrák vlastně dělá.

1155
01:21:15,779 --> 01:21:17,819
Jo, nepředstavujte si zatím žádnou

1156
01:21:17,920 --> 01:21:19,739
prostě magii. Magie je

1157
01:21:20,119 --> 01:21:23,600
jak ty data správně umístit do té databáze,

1158
01:21:23,659 --> 01:21:28,020
protože vy ty data musíte rozdělit do nějakých čanků,

1159
01:21:28,020 --> 01:21:30,460
pokud se bavujeme o vektrový databáze.

1160
01:21:30,699 --> 01:21:34,380
A tam je poměrně komplikovaný, jak velký ty čanky uděláte,

1161
01:21:34,420 --> 01:21:36,479
oni by měli být tak stejně velký.

1162
01:21:36,699 --> 01:21:39,739
A teď samozřejmě vaše dokumenty nejsou stejně velký,

1163
01:21:40,000 --> 01:21:41,180
takže jak vy je budete...

1164
01:21:42,239 --> 01:21:48,059
vlastně čankovat k sobě tak, abyste ten dokument neusekli třeba v nějaký důležitý části,

1165
01:21:48,440 --> 01:21:53,340
aby ten dokument, tu část toho dokumentu, když on si vlastně vytáhne z té databáze,

1166
01:21:53,479 --> 01:21:57,239
aby obsahovala tu odpověď a nekončila někde třeba v půlce věty,

1167
01:21:58,300 --> 01:22:02,380
pak zase tím se ovlivňují ty výsledky, co to na RAG umí nebo neumí.

1168
01:22:02,880 --> 01:22:07,619
Takže finetuning s tím, že ho naučíte tu dokumentaci, je jeden způsob.

1169
01:22:07,619 --> 01:22:11,440
Je to samozřejmě, když to porovnáváme, bude se na něm zamýšlet trošku,

1170
01:22:11,739 --> 01:22:15,800
tady musíte investovat nějaké peníze do toho, abyste ten model finetunovali.

1171
01:22:15,940 --> 01:22:22,659
Na druhou stranu ušetříte peníze, protože nemusíte vždycky připlácávat

1172
01:22:24,079 --> 01:22:27,440
do toho kontextu ty dokumenty, to znamená, že...

1173
01:22:27,899 --> 01:22:30,140
Pokud budete používat rack,

1174
01:22:30,220 --> 01:22:32,119
tak se vám to v dlouhodobém horizontu

1175
01:22:32,119 --> 01:22:33,699
to bude pro vás dražší

1176
01:22:34,220 --> 01:22:36,140
než ten fine tuning.

1177
01:22:36,220 --> 01:22:37,479
Protože vždycky ten

1178
01:22:37,479 --> 01:22:39,880
počet tokenů,

1179
01:22:39,960 --> 01:22:41,199
který půjdou do toho modelu,

1180
01:22:41,760 --> 01:22:46,319
bude ta otázka včetně všech těch dokumentů relevantních,

1181
01:22:46,319 --> 01:22:48,539
což celkem nabobtná.

1182
01:22:48,539 --> 01:22:54,940
A pokud tohle to budete používat často pro komunikaci služovatelů

1183
01:22:54,979 --> 01:22:57,039
nebo to budete používat na nějaké webové stránce

1184
01:22:57,319 --> 01:23:00,659
a vždycky si budete šádat do té databáze pro nějaké relevantní dokumenty,

1185
01:23:00,659 --> 01:23:04,440
tak vám může velmi rychle nabobtnat ten budget.

1186
01:23:04,699 --> 01:23:07,260
Kdežto ten fine tuning vlastně natrénujete jednou,

1187
01:23:07,420 --> 01:23:10,720
ten model už by si to měl zapamatovat, měl by to mít v těch váhách,

1188
01:23:11,119 --> 01:23:14,020
a pak už vlastně, když s ním komunikuje uživatel,

1189
01:23:14,020 --> 01:23:16,239
tak vlastně už tam jde jenom ta uživotová otázka

1190
01:23:16,619 --> 01:23:22,020
a ten model vlastně vám vrátí už tu odpověď bez toho,

1191
01:23:22,020 --> 01:23:26,059
aniž byste museli tam posílat velké množství dat.

1192
01:23:26,059 --> 01:23:30,420
To znamená, že ta obecná, to obecní doporučení je,

1193
01:23:30,460 --> 01:23:36,859
ano, použijte na to rak, nicméně lidi už přišli na to,

1194
01:23:36,859 --> 01:23:42,159
že rak není vlastně už ani termín, dřív to byl hrozný termín,

1195
01:23:42,479 --> 01:23:48,020
Dneska už to berou lidi jenom jako tool, který může použít AI agent

1196
01:23:48,020 --> 01:23:50,279
a ten tool se jmenuje databáze.

1197
01:23:50,279 --> 01:23:54,500
Dneska už se tomu ani, jako najdete samozřejmě články o RUGu,

1198
01:23:54,500 --> 01:24:00,100
ale už se to nebere jako tak velký topic, jako to bylo třeba rok zpátky.

1199
01:24:00,760 --> 01:24:05,420
Rok a půl zpátky to bylo RUG na stejný úrovni jako AI agent.

1200
01:24:06,220 --> 01:24:11,340
A dneska už je RUG jenom nějakej tool, jeden z toolů, který ten AI agent může použít.

1201
01:24:11,720 --> 01:24:14,940
že firmní dokumenty nasypat do nějaké vektorové databáze.

1202
01:24:14,940 --> 01:24:25,340
Ano, bylo by to asi nejdoporučovanější způsob.

1203
01:24:26,239 --> 01:24:27,739
Ale jsem zvěděl, co na to řekne Lukáš,

1204
01:24:27,779 --> 01:24:30,159
jestli on by raději trénoval model nebo využil rak.

1205
01:24:30,199 --> 01:24:32,399
Tam hrozně záleží na množství těch dat

1206
01:24:33,340 --> 01:24:37,020
a na zkušenosti lidí, který budou ten fine tuning provádět.

1207
01:24:37,739 --> 01:24:46,020
Pokud to dáte nějakému prostě, nebo amatérovi a budete vlastně po něm chtít dělat ten fine tuning toho modelu,

1208
01:24:46,059 --> 01:24:51,380
on vlastně nebude vidět, jak připravit pořádně ten dataset, tak jenom budete ztrácet peníze.

1209
01:24:51,760 --> 01:24:57,399
V tom případě, pokud ten tým není tak zkušenej, tak bych doporučoval spíš ten RAC,

1210
01:24:57,460 --> 01:25:01,420
protože tam už zase těch dokumentů o tom, jak ten RAC dělat, je spousta.

1211
01:25:02,399 --> 01:25:05,880
A to obecní doporučení tý komunity je

1212
01:25:05,880 --> 01:25:09,659
spát to do ragu. Já jsem ale viděl i moc hezký

1213
01:25:09,699 --> 01:25:13,739
natrénovanej model Fine Tuningem, který prostě měl

1214
01:25:13,819 --> 01:25:16,760
ty dokumenty vlastně v těch váhách a byl velmi

1215
01:25:17,340 --> 01:25:21,479
hezky schopnej odpovídat na ty odpovědi

1216
01:25:21,840 --> 01:25:25,380
a bylo to velmi efektivní, protože jste nemuseli pořád

1217
01:25:25,659 --> 01:25:29,159
posílat ten velký množství dat. Bylo to opravdu

1218
01:25:29,720 --> 01:25:33,699
Ale dělal to člověk, který už s tím má dlouholetí zkušenosti.

1219
01:25:33,739 --> 01:25:35,539
No dlouholetí, ono to zase tak dlouho tady není,

1220
01:25:35,979 --> 01:25:39,920
ale on sám natrénoval už spoustu neuronových sítí.

1221
01:25:41,479 --> 01:25:42,899
Takže bylo by dobré doplnit taky,

1222
01:25:42,899 --> 01:25:44,880
o jak velké dokumentaci se bavíme.

1223
01:25:44,880 --> 01:25:46,760
Určitě.

1224
01:25:47,720 --> 01:25:49,579
Ten moderation check pro naše účely,

1225
01:25:49,579 --> 01:25:50,840
ale můžeme ignorovat, ne?

1226
01:25:50,840 --> 01:25:53,000
Když to nebudeme dávat do světa dětem.

1227
01:25:53,239 --> 01:25:57,680
To nemůžete, protože vy budete fine-tunovat ten model.

1228
01:25:57,699 --> 01:26:03,579
A ten dataset, pokud bude obsahovat tyhle hate speeche a tak dále,

1229
01:26:03,760 --> 01:26:07,800
tak OpenAI fine-tuning vám to zamítne.

1230
01:26:07,800 --> 01:26:11,979
Vy tam na uploadujete ten soubor, dáte klik, pustit fine-tuning

1231
01:26:12,300 --> 01:26:14,559
a za 5 minut se na to podíváte a tam bude error.

1232
01:26:15,180 --> 01:26:16,659
Data obsahují hate speech.

1233
01:26:17,039 --> 01:26:19,800
A žádný fine-tunovaný model z toho nedostanete.

1234
01:26:20,619 --> 01:26:25,779
Rack si myslím nemá úplně limit, myslím, že jde o jedno PDF do X terabajtů.

1235
01:26:25,779 --> 01:26:30,440
Jo, rack musíte vždycky čankovat, to znamená, že rack nemá úplně limit,

1236
01:26:30,479 --> 01:26:34,340
protože vy vždycky vytvoříte určitý čanky z toho.

1237
01:26:34,500 --> 01:26:38,979
Vy nikdy tam jakoby nedáte celý 40 gigovej soubor,

1238
01:26:39,059 --> 01:26:42,800
vždycky z toho vytvoříte nějaký čanky 100 megabitovým.

1239
01:26:43,460 --> 01:26:46,500
Pak je otázka práv k firmním dokumentům.

1240
01:26:46,899 --> 01:26:50,619
Já asi už přejdu, zase budu pokračovat i tady těch otázek docela dost,

1241
01:26:50,640 --> 01:26:54,760
tak já to pak zkusím projít na konci nějakým rychloformátům

1242
01:26:54,760 --> 01:26:56,960
a ještě pak budu muset dělat něco do práce,

1243
01:26:57,520 --> 01:26:59,680
že dneska to nebude tak dlouhý.

1244
01:27:01,840 --> 01:27:15,739
Tak, ukázali jsme si teda domenovou znalost, ukázali jsme si toho Joe'a Elgina, teď se podíváme na tooly, protože za mě prostě ty tooly je to velmi důležitá schopnost, kterou ty modely prostě za mě musí mít.

1245
01:27:15,739 --> 01:27:23,420
Pokud u mě ten model neumí tools, tool use, tak mě nezajímá opřímně.

1246
01:27:24,500 --> 01:27:29,039
Takže se podíváme, jak případně dotrénovat ten tool use,

1247
01:27:29,039 --> 01:27:31,739
pokud byste našli model, který se vám opravdu líbí

1248
01:27:32,119 --> 01:27:33,319
a tool use neumí.

1249
01:27:33,600 --> 01:27:40,659
Příkladem může teďkon bejt nějaká O1, O3,

1250
01:27:41,059 --> 01:27:42,819
nebo teď přemýšlím ten deep seek,

1251
01:27:42,940 --> 01:27:45,800
tam jsme viděli v tom tokenizoru zrovna ty tokeny

1252
01:27:45,859 --> 01:27:47,819
na ten tool use.

1253
01:27:48,079 --> 01:27:50,680
Nejsem si jistý, jestli to teda tam jenom je,

1254
01:27:51,079 --> 01:27:53,319
anebo on to opravdu umí,

1255
01:27:53,940 --> 01:27:54,940
nedat bych spekuloval.

1256
01:27:54,960 --> 01:27:59,119
Nicméně existují modely, které Toolius nemají,

1257
01:27:59,199 --> 01:28:01,399
takže si ukážeme, jak ho to doučit.

1258
01:28:01,720 --> 01:28:04,479
A to doučení může proběhnout dvouma způsobama.

1259
01:28:05,960 --> 01:28:08,399
Jedno je takový neoficiální,

1260
01:28:08,859 --> 01:28:12,440
nebo ten způsob můžete naučit jakýkoliv model,

1261
01:28:12,440 --> 01:28:15,440
nehledě na to, jestli v tokenajzru má speciální tokeny

1262
01:28:15,440 --> 01:28:17,340
na Toolius nebo ne.

1263
01:28:18,760 --> 01:28:22,159
A tenhle ten new způsob je zaměřený na modely,

1264
01:28:22,500 --> 01:28:29,659
které v tokenizoru mají speciální tokeny na tool use.

1265
01:28:29,739 --> 01:28:36,479
Zase, když tě já tady odevřu ty tokenizory,

1266
01:28:37,340 --> 01:28:42,940
nebo obsah toho tokenizoru, řekněme.

1267
01:28:49,059 --> 01:28:50,880
Tak, bude asi dlouhý, než to projdu.

1268
01:28:50,960 --> 01:28:53,600
Já myslím, že budeme měli na začátku nebo na konci.

1269
01:28:57,039 --> 01:28:57,739
Tady je.

1270
01:28:59,420 --> 01:29:03,159
Tak třeba LAMA3instruct.

1271
01:29:03,859 --> 01:29:08,920
A žádný jako speciální tokeny na tool tady nevidím.

1272
01:29:09,079 --> 01:29:11,760
Vzhledem k tomu, že ty tokeny speciální,

1273
01:29:11,880 --> 01:29:13,420
jejich vypadají zhruba takhle.

1274
01:29:14,500 --> 01:29:16,859
Tak tady žádný speciální token na tool nevidím.

1275
01:29:16,940 --> 01:29:18,859
Takže třeba ta LAMA3,
=================


Important: Translate all titles to English.
Important: No explanation, no comments, only valid JSON as output.